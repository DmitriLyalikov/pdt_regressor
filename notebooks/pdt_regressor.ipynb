{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### PDT XGBoost Regression Model\n",
    "#### Data:\n",
    "* This model takes the labeled set of features of the pendant drop profile and becomes a function of beta. Input features include Drop Height, Capillary Radius, R-s, R-e, and Smax. The current model is trained, tested, and tuned on dataset (data/pdt-dataset.csv) which has 2500 entries.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV, StratifiedKFold\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from xgboost import XGBRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "   Drop Height  Capillary Radius     R-s      R-e     Smax    Beta\n0      2943094            682425  886383  1090550  3590000  400000\n1      3033584            668466  892828  1087285  3689763  400000\n2      3130900            665749  879073  1084616  3789526  400000\n3      3231715            672651  892636  1084586  3889289  400000\n4      3338794            690917  884025  1088827  3989053  400000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Drop Height</th>\n      <th>Capillary Radius</th>\n      <th>R-s</th>\n      <th>R-e</th>\n      <th>Smax</th>\n      <th>Beta</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2943094</td>\n      <td>682425</td>\n      <td>886383</td>\n      <td>1090550</td>\n      <td>3590000</td>\n      <td>400000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3033584</td>\n      <td>668466</td>\n      <td>892828</td>\n      <td>1087285</td>\n      <td>3689763</td>\n      <td>400000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3130900</td>\n      <td>665749</td>\n      <td>879073</td>\n      <td>1084616</td>\n      <td>3789526</td>\n      <td>400000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3231715</td>\n      <td>672651</td>\n      <td>892636</td>\n      <td>1084586</td>\n      <td>3889289</td>\n      <td>400000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3338794</td>\n      <td>690917</td>\n      <td>884025</td>\n      <td>1088827</td>\n      <td>3989053</td>\n      <td>400000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I am multiplying all elements by 10^6, to keep float integrity when using gridsearchCV as int64\n",
    "df = pd.read_csv('../data/pdt-dataset.csv').apply(lambda x: x*1000000).astype('int64')\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "0    400000\n1    400000\n2    400000\n3    400000\n4    400000\nName: Beta, dtype: int64"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop('Beta', axis=1)\n",
    "y = df['Beta']\n",
    "\n",
    "# Stratified fold includes the same percentage of target values in each fold.\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=2)\n",
    "y.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# This function takes a list of hyperparameter configs and finds the best one.\n",
    "def grid_search(params, random=False):\n",
    "    # Initialize XGB Regressor with objective='reg:squarederror' (MSE)\n",
    "    xgb = XGBRegressor(booster='gbtree', objective='reg:squarederror',\n",
    "    random_state=2)\n",
    "    if random:\n",
    "        grid = RandomizedSearchCV(xgb, params, cv=kfold, n_iter=20, n_jobs=-1)\n",
    "    else:\n",
    "        grid = GridSearchCV(xgb, params, cv=kfold, n_jobs=-1)\n",
    "    grid.fit(X, y)\n",
    "    best_params = grid.best_params_\n",
    "    print(\"Best params:\", best_params)\n",
    "    best_score = grid.best_score_\n",
    "    print(\"Training score: {:.3f}\".format(best_score))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'n_estimators': 800}\n",
      "Training score: 0.999\n"
     ]
    }
   ],
   "source": [
    "grid_search(params={'n_estimators': [100, 200, 400, 800]})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'learning_rate': 0.1}\n",
      "Training score: 0.999\n"
     ]
    }
   ],
   "source": [
    "grid_search(params={'learning_rate':[0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5]})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'max_depth': 5}\n",
      "Training score: 0.999\n"
     ]
    }
   ],
   "source": [
    "grid_search(params={'max_depth':[2, 3, 5, 6, 8]})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tuned XGBoost Regressor\n",
    "* n-estimators: 800\n",
    "* learning_rate=.1\n",
    "* max_depth = 5\n",
    "\n",
    "Accuracy score on test data (.999), MSE: (0.0034324513493428823)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0034324513493428823\n"
     ]
    }
   ],
   "source": [
    "# Build, train, test, and save our model\n",
    "xgb = XGBRegressor(booster='gbtree', objective='reg:squarederror',\n",
    "    random_state=2, learning_rate=.1, n_estimators=800, max_depth=5)\n",
    "\n",
    "df = pd.read_csv('../data/pdt-dataset.csv')\n",
    "X = df.drop('Beta', axis=1)\n",
    "y = df['Beta']\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "y_pred = xgb.predict(X_test)\n",
    "\n",
    "reg_mse = mean_squared_error(y_test, y_pred)\n",
    "reg_rmse = np.sqrt(reg_mse)\n",
    "print(reg_rmse)\n",
    "\n",
    "with open(\"../models/pdt-regression-model.pkl\", 'wb') as f:\n",
    "    pickle.dump(xgb, f)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "An example of how to use saved models."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# Load the model from models folder\n",
    "with open(\"../models/pdt-regression-model.pkl\", 'rb') as f:\n",
    "    model = pickle.load(f)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Experimenting with wider beta range on same model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.004374367554479346\n"
     ]
    }
   ],
   "source": [
    "# Build, train, test, and save our model\n",
    "xgb = XGBRegressor(booster='gbtree', objective='reg:squarederror',\n",
    "    random_state=2, learning_rate=.1, n_estimators=800, max_depth=5)\n",
    "\n",
    "df = pd.read_csv('../data/pdt-dataset-wider-beta.csv')\n",
    "X = df.drop('Beta', axis=1)\n",
    "y = df['Beta']\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "y_pred = xgb.predict(X_test)\n",
    "\n",
    "reg_mse = mean_squared_error(y_test, y_pred)\n",
    "reg_rmse = np.sqrt(reg_mse)\n",
    "print(reg_rmse)\n",
    "\n",
    "#with open(\"../models/pdt-regression-model.pkl\", 'wb') as f:\n",
    "#    pickle.dump(xgb, f)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Experiment with same model but without Smax as training data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.004334942946277289\n"
     ]
    }
   ],
   "source": [
    "# Build, train, test, and save our model\n",
    "xgb = XGBRegressor(booster='gbtree', objective='reg:squarederror',\n",
    "    random_state=2, learning_rate=.1, n_estimators=800, max_depth=5)\n",
    "\n",
    "df = pd.read_csv('../data/pdt-dataset-wider-beta-no-Smax.csv')\n",
    "X = df.drop('Beta', axis=1)\n",
    "y = df['Beta']\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "y_pred = xgb.predict(X_test)\n",
    "\n",
    "reg_mse = mean_squared_error(y_test, y_pred)\n",
    "reg_rmse = np.sqrt(reg_mse)\n",
    "print(reg_rmse)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
