{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### PDT XGBoost Regression Model\n",
    "#### Data:\n",
    "* This model takes the labeled set of features of the pendant drop profile and becomes a function of beta. Input features include Drop Height, Capillary Radius, R-s, R-e, and Smax. The current model is trained, tested, and tuned on dataset (data/pdt-dataset.csv) which has 2500 entries.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV, StratifiedKFold\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from xgboost import XGBRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "   Drop Height  Capillary Radius     R-s      R-e     Smax    Beta\n0      2943094            682425  886383  1090550  3590000  400000\n1      3033584            668466  892828  1087285  3689763  400000\n2      3130900            665749  879073  1084616  3789526  400000\n3      3231715            672651  892636  1084586  3889289  400000\n4      3338794            690917  884025  1088827  3989053  400000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Drop Height</th>\n      <th>Capillary Radius</th>\n      <th>R-s</th>\n      <th>R-e</th>\n      <th>Smax</th>\n      <th>Beta</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2943094</td>\n      <td>682425</td>\n      <td>886383</td>\n      <td>1090550</td>\n      <td>3590000</td>\n      <td>400000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3033584</td>\n      <td>668466</td>\n      <td>892828</td>\n      <td>1087285</td>\n      <td>3689763</td>\n      <td>400000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3130900</td>\n      <td>665749</td>\n      <td>879073</td>\n      <td>1084616</td>\n      <td>3789526</td>\n      <td>400000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3231715</td>\n      <td>672651</td>\n      <td>892636</td>\n      <td>1084586</td>\n      <td>3889289</td>\n      <td>400000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3338794</td>\n      <td>690917</td>\n      <td>884025</td>\n      <td>1088827</td>\n      <td>3989053</td>\n      <td>400000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I am multiplying all elements by 10^6, to keep float integrity when using gridsearchCV as int64\n",
    "df = pd.read_csv('../data/pdt-dataset.csv').apply(lambda x: x*1000000).astype('int64')\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "0    400000\n1    400000\n2    400000\n3    400000\n4    400000\nName: Beta, dtype: int64"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop('Beta', axis=1)\n",
    "y = df['Beta']\n",
    "\n",
    "# Stratified fold includes the same percentage of target values in each fold.\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=2)\n",
    "y.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# This function takes a list of hyperparameter configs and finds the best one.\n",
    "def grid_search(params, random=False):\n",
    "    # Initialize XGB Regressor with objective='reg:squarederror' (MSE)\n",
    "    xgb = XGBRegressor(booster='gbtree', objective='reg:squarederror',\n",
    "    random_state=2)\n",
    "    if random:\n",
    "        grid = RandomizedSearchCV(xgb, params, cv=kfold, n_iter=20, n_jobs=-1)\n",
    "    else:\n",
    "        grid = GridSearchCV(xgb, params, cv=kfold, n_jobs=-1)\n",
    "    grid.fit(X, y)\n",
    "    best_params = grid.best_params_\n",
    "    print(\"Best params:\", best_params)\n",
    "    best_score = grid.best_score_\n",
    "    print(\"Training score: {:.3f}\".format(best_score))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'n_estimators': 800}\n",
      "Training score: 0.999\n"
     ]
    }
   ],
   "source": [
    "grid_search(params={'n_estimators': [100, 200, 400, 800]})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'learning_rate': 0.1}\n",
      "Training score: 0.999\n"
     ]
    }
   ],
   "source": [
    "grid_search(params={'learning_rate':[0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5]})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'max_depth': 5}\n",
      "Training score: 0.999\n"
     ]
    }
   ],
   "source": [
    "grid_search(params={'max_depth':[2, 3, 5, 6, 8]})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tuned XGBoost Regressor\n",
    "* n-estimators: 800\n",
    "* learning_rate=.1\n",
    "* max_depth = 5\n",
    "\n",
    "Accuracy score on test data (.999), MSE: (0.0034324513493428823)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0034324513493428823\n"
     ]
    }
   ],
   "source": [
    "# Build, train, test, and save our model\n",
    "xgb = XGBRegressor(booster='gbtree', objective='reg:squarederror',\n",
    "    random_state=2, learning_rate=.1, n_estimators=800, max_depth=5)\n",
    "\n",
    "df = pd.read_csv('../data/pdt-dataset.csv')\n",
    "X = df.drop('Beta', axis=1)\n",
    "y = df['Beta']\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "y_pred = xgb.predict(X_test)\n",
    "\n",
    "reg_mse = mean_squared_error(y_test, y_pred)\n",
    "reg_rmse = np.sqrt(reg_mse)\n",
    "print(reg_rmse)\n",
    "\n",
    "with open(\"../models/pdt-regression-model.pkl\", 'wb') as f:\n",
    "    pickle.dump(xgb, f)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "An example of how to use saved models."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# Load the model from models folder\n",
    "with open(\"../models/pdt-regression-model.pkl\", 'rb') as f:\n",
    "    model = pickle.load(f)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Experimenting with wider beta range on same model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.004374367554479346\n",
      "0.00474501474542218\n"
     ]
    }
   ],
   "source": [
    "# Build, train, test, and save our model\n",
    "xgb = XGBRegressor(booster='gbtree', objective='reg:squarederror',\n",
    "    random_state=2, learning_rate=.1, n_estimators=800, max_depth=5)\n",
    "\n",
    "df = pd.read_csv('../data/pdt-dataset-wider-beta.csv')\n",
    "X = df.drop('Beta', axis=1)\n",
    "y = df['Beta']\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "y_pred = xgb.predict(X_test)\n",
    "\n",
    "reg_mse = mean_squared_error(y_test, y_pred)\n",
    "reg_rmse = np.sqrt(reg_mse)\n",
    "print(reg_rmse)\n",
    "\n",
    "\n",
    "# let's test on original data\n",
    "df = pd.read_csv('../data/pdt-dataset.csv')\n",
    "X = df.drop('Beta', axis=1)\n",
    "y = df['Beta']\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "y_pred = xgb.predict(X_test)\n",
    "\n",
    "reg_mse = mean_squared_error(y_test, y_pred)\n",
    "reg_rmse = np.sqrt(reg_mse)\n",
    "print(reg_rmse)\n",
    "#with open(\"../models/pdt-regression-model.pkl\", 'wb') as f:\n",
    "#    pickle.dump(xgb, f)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Experiment with same model but without Smax as training data and larger range of beta"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.004334942946277289\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Feature shape mismatch, expected: 4, got 5",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[13], line 25\u001B[0m\n\u001B[0;32m     21\u001B[0m y \u001B[38;5;241m=\u001B[39m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mBeta\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m     22\u001B[0m X_train, X_test, y_train, y_test \u001B[38;5;241m=\u001B[39m train_test_split(\n\u001B[0;32m     23\u001B[0m X, y, test_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.3\u001B[39m, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m42\u001B[39m)\n\u001B[1;32m---> 25\u001B[0m y_pred \u001B[38;5;241m=\u001B[39m \u001B[43mxgb\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_test\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     27\u001B[0m reg_mse \u001B[38;5;241m=\u001B[39m mean_squared_error(y_test, y_pred)\n\u001B[0;32m     28\u001B[0m reg_rmse \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39msqrt(reg_mse)\n",
      "File \u001B[1;32m~\\PycharmProjects\\pdt_regressor\\venv\\lib\\site-packages\\xgboost\\sklearn.py:1114\u001B[0m, in \u001B[0;36mXGBModel.predict\u001B[1;34m(self, X, output_margin, ntree_limit, validate_features, base_margin, iteration_range)\u001B[0m\n\u001B[0;32m   1112\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_can_use_inplace_predict():\n\u001B[0;32m   1113\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1114\u001B[0m         predts \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_booster\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minplace_predict\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1115\u001B[0m \u001B[43m            \u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1116\u001B[0m \u001B[43m            \u001B[49m\u001B[43miteration_range\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43miteration_range\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1117\u001B[0m \u001B[43m            \u001B[49m\u001B[43mpredict_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmargin\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43moutput_margin\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mvalue\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1118\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmissing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmissing\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1119\u001B[0m \u001B[43m            \u001B[49m\u001B[43mbase_margin\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbase_margin\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1120\u001B[0m \u001B[43m            \u001B[49m\u001B[43mvalidate_features\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidate_features\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1121\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1122\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m _is_cupy_array(predts):\n\u001B[0;32m   1123\u001B[0m             \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mcupy\u001B[39;00m  \u001B[38;5;66;03m# pylint: disable=import-error\u001B[39;00m\n",
      "File \u001B[1;32m~\\PycharmProjects\\pdt_regressor\\venv\\lib\\site-packages\\xgboost\\core.py:2269\u001B[0m, in \u001B[0;36mBooster.inplace_predict\u001B[1;34m(self, data, iteration_range, predict_type, missing, validate_features, base_margin, strict_shape)\u001B[0m\n\u001B[0;32m   2265\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[0;32m   2266\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`shape` attribute is required when `validate_features` is True.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   2267\u001B[0m         )\n\u001B[0;32m   2268\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(data\u001B[38;5;241m.\u001B[39mshape) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_features() \u001B[38;5;241m!=\u001B[39m data\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m]:\n\u001B[1;32m-> 2269\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   2270\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFeature shape mismatch, expected: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_features()\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   2271\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgot \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdata\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   2272\u001B[0m         )\n\u001B[0;32m   2274\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m   2275\u001B[0m     _array_interface,\n\u001B[0;32m   2276\u001B[0m     _is_cudf_df,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   2279\u001B[0m     _transform_pandas_df,\n\u001B[0;32m   2280\u001B[0m )\n\u001B[0;32m   2282\u001B[0m enable_categorical \u001B[38;5;241m=\u001B[39m _has_categorical(\u001B[38;5;28mself\u001B[39m, data)\n",
      "\u001B[1;31mValueError\u001B[0m: Feature shape mismatch, expected: 4, got 5"
     ]
    }
   ],
   "source": [
    "# Build, train, test, and save our model\n",
    "xgb = XGBRegressor(booster='gbtree', objective='reg:squarederror',\n",
    "    random_state=2, learning_rate=.1, n_estimators=800, max_depth=5)\n",
    "\n",
    "df = pd.read_csv('../data/pdt-dataset-wider-beta-no-Smax.csv')\n",
    "X = df.drop('Beta', axis=1)\n",
    "y = df['Beta']\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "y_pred = xgb.predict(X_test)\n",
    "\n",
    "reg_mse = mean_squared_error(y_test, y_pred)\n",
    "reg_rmse = np.sqrt(reg_mse)\n",
    "print(reg_rmse)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
