{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### PDT XGBoost Regression Model\n",
    "#### Data:\n",
    "* This model takes the labeled set of features of the pendant drop profile and becomes a function of beta. Input features include Drop Height, Capillary Radius, R-s, R-e, and Smax. The current model is trained, tested, and tuned on dataset (data/pdt-dataset.csv) which has 2500 entries.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV, StratifiedKFold\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "   Drop Height  Capillary Radius     R-s      R-e     Smax    Beta\n0      2931984            675340  890067  1085611  3590000  400000\n1      3041870            673539  885918  1094985  3689763  400000\n2      3131424            666058  889661  1085394  3789526  400000\n3      3235418            674748  884866  1085809  3889289  400000\n4      3335846            689308  896088  1086557  3989053  400000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Drop Height</th>\n      <th>Capillary Radius</th>\n      <th>R-s</th>\n      <th>R-e</th>\n      <th>Smax</th>\n      <th>Beta</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2931984</td>\n      <td>675340</td>\n      <td>890067</td>\n      <td>1085611</td>\n      <td>3590000</td>\n      <td>400000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3041870</td>\n      <td>673539</td>\n      <td>885918</td>\n      <td>1094985</td>\n      <td>3689763</td>\n      <td>400000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3131424</td>\n      <td>666058</td>\n      <td>889661</td>\n      <td>1085394</td>\n      <td>3789526</td>\n      <td>400000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3235418</td>\n      <td>674748</td>\n      <td>884866</td>\n      <td>1085809</td>\n      <td>3889289</td>\n      <td>400000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3335846</td>\n      <td>689308</td>\n      <td>896088</td>\n      <td>1086557</td>\n      <td>3989053</td>\n      <td>400000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I am multiplying all elements by 10^6, to keep float integrity when using gridsearchCV as int64\n",
    "df = pd.read_csv('../data/pdt-dataset.csv').apply(lambda x: x*1000000).astype('int64')\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "0    400000\n1    400000\n2    400000\n3    400000\n4    400000\nName: Beta, dtype: int64"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This model predicts Beta given a Pendant Drop Profile\n",
    "X = df.drop('Beta', axis=1)\n",
    "y = df['Beta']\n",
    "\n",
    "# Stratified fold includes the same percentage of target values in each fold.\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=2)\n",
    "y.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "# This function takes a list of hyperparameter configs and finds the best one.\n",
    "def grid_search(params, random=False):\n",
    "    # Initialize XGB Regressor with objective='reg:squarederror' (MSE)\n",
    "    xgb = XGBRegressor(booster='gbtree', objective='reg:squarederror',\n",
    "    random_state=2)\n",
    "    if random:\n",
    "        grid = RandomizedSearchCV(xgb, params, cv=kfold, n_iter=20, n_jobs=-1)\n",
    "    else:\n",
    "        grid = GridSearchCV(xgb, params, cv=kfold, n_jobs=-1)\n",
    "    grid.fit(X, y)\n",
    "    best_params = grid.best_params_\n",
    "    print(\"Best params:\", best_params)\n",
    "    best_score = grid.best_score_\n",
    "    print(\"Training score: {:.3f}\".format(best_score))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'n_estimators': 800}\n",
      "Training score: 0.999\n"
     ]
    }
   ],
   "source": [
    "grid_search(params={'n_estimators': [100, 200, 400, 800]})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'learning_rate': 0.1}\n",
      "Training score: 0.999\n"
     ]
    }
   ],
   "source": [
    "grid_search(params={'learning_rate':[0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5]})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'max_depth': 8}\n",
      "Training score: 0.999\n"
     ]
    }
   ],
   "source": [
    "grid_search(params={'max_depth':[2, 3, 5, 6, 8]})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tuned XGBoost Regressor\n",
    "* n-estimators: 800\n",
    "* learning_rate=.1\n",
    "* max_depth = 5\n",
    "\n",
    "Accuracy score on test data (.999), RMSE: (0.0034324513493428823)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.003500566413769064\n",
      "[1.8704833e-02 2.3043489e-04 9.7737092e-01 3.1523095e-03 5.4150441e-04]\n"
     ]
    }
   ],
   "source": [
    "# Build, train, test, and save our model\n",
    "xgb = XGBRegressor(booster='gbtree', objective='reg:squarederror',\n",
    "    random_state=2, learning_rate=.1, n_estimators=800, max_depth=5)\n",
    "\n",
    "df = pd.read_csv('../data/pdt-dataset.csv')\n",
    "X = df.drop('Beta', axis=1)\n",
    "y = df['Beta']\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "y_pred = xgb.predict(X_test)\n",
    "\n",
    "reg_mse = mean_squared_error(y_test, y_pred)\n",
    "reg_rmse = np.sqrt(reg_mse)\n",
    "\n",
    "print(reg_rmse)\n",
    "print(xgb.feature_importances_)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Save our previous model to models folder\n",
    "with open(\"../models/pdt-regression-model.pkl\", 'wb') as f:\n",
    "    pickle.dump(xgb, f)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "An example of how to use saved models."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load the model from models folder\n",
    "with open(\"../models/pdt-regression-model.pkl\", 'rb') as f:\n",
    "    model = pickle.load(f)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Experimenting with wider beta range data set (.1-.8) on same model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Build, train, test, and save our model\n",
    "xgb = XGBRegressor(booster='gbtree', objective='reg:squarederror',\n",
    "    random_state=2, learning_rate=.1, n_estimators=800, max_depth=5)\n",
    "\n",
    "df = pd.read_csv('../data/pdt-dataset-wider-beta.csv')\n",
    "X = df.drop('Beta', axis=1)\n",
    "y = df['Beta']\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "y_pred = xgb.predict(X_test)\n",
    "\n",
    "reg_mse = mean_squared_error(y_test, y_pred)\n",
    "reg_rmse = np.sqrt(reg_mse)\n",
    "print(reg_rmse)\n",
    "\n",
    "\n",
    "# let's test on original data\n",
    "df = pd.read_csv('../data/pdt-dataset.csv')\n",
    "X = df.drop('Beta', axis=1)\n",
    "y = df['Beta']\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "y_pred = xgb.predict(X_test)\n",
    "\n",
    "reg_mse = mean_squared_error(y_test, y_pred)\n",
    "reg_rmse = np.sqrt(reg_mse)\n",
    "print(reg_rmse)\n",
    "print(xgb.feature_importances_)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Experiment with same model but without Smax as training data and larger range of beta"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Build, train, test, and save our model\n",
    "xgb = XGBRegressor(booster='gbtree', objective='reg:squarederror',\n",
    "    random_state=2, learning_rate=.1, n_estimators=800, max_depth=5)\n",
    "\n",
    "df = pd.read_csv('../data/pdt-dataset-wider-beta-no-Smax.csv')\n",
    "X = df.drop('Beta', axis=1)\n",
    "y = df['Beta']\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "y_pred = xgb.predict(X_test)\n",
    "\n",
    "reg_mse = mean_squared_error(y_test, y_pred)\n",
    "reg_rmse = np.sqrt(reg_mse)\n",
    "print(reg_rmse)\n",
    "print(xgb.feature_importances_)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
